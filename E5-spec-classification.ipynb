{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-membership",
   "metadata": {},
   "source": [
    "# E5-Spectrogram classification 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-biotechnology",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-palace",
   "metadata": {},
   "source": [
    "### 데이터 다운받기 (1.6G 대용량)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-dinner",
   "metadata": {},
   "source": [
    "mkdir -p ~/aiffel/speech_recognition/data\n",
    "mkdir -p ~/aiffel/speech_recognition/models\n",
    "wget https://aiffelstaticdev.blob.core.windows.net/dataset/speech_wav_8000.npz -P ~/aiffel/speech_recognition/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "documentary-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave data shape :  (50620, 8000)\n",
      "Label data shape :  (50620, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/aiffel/speech_recognition/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"Wave data shape : \", speech_data[\"wav_vals\"].shape) # 50620*8000 행렬이란 소리 아닌가..8000*1사이즈 데이터 50620개\n",
    "print(\"Label data shape : \", speech_data[\"label_vals\"].shape) # 50620 by 1 행렬... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-mathematics",
   "metadata": {},
   "source": [
    "### 데이터 확인해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "threaded-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand num :  13818\n",
      "Wave data shape :  (8000,)\n",
      "label data shape :  (1,)\n",
      "label :  ['right']\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import random\n",
    "\n",
    "# 데이터 선택 (랜덤하게 선택하고 있으니, 여러번 실행해 보세요)\n",
    "rand = random.randint(0, len(speech_data[\"wav_vals\"]))  # 실행할 때마다 'rand num','label' 바뀜\n",
    "print(\"rand num : \", rand)\n",
    "\n",
    "sr = 8000 # 1초동안 재생되는 샘플의 갯수\n",
    "data1 = speech_data[\"wav_vals\"]  # 웨이브 데이터??\n",
    "data1[rand]\n",
    "data2 = speech_data[\"label_vals\"]\n",
    "data2[rand]\n",
    "print(\"Wave data shape : \", data1[rand].shape)\n",
    "print(\"label data shape : \", data2[rand].shape)\n",
    "print(\"label : \", data2[rand])\n",
    "\n",
    "#ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-delay",
   "metadata": {},
   "source": [
    "### Spectrogram 으로 변환 후, 입력 데이터에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-petroleum",
   "metadata": {},
   "source": [
    "* wav 데이터를 해석하는 방법 중 하나로, 일정 시간동안 wav 데이터 안의 다양한 주파수들이 얼마나 포함되어 있는 지를 보여줌  \n",
    "* X축은 시간, Y축은 주파수  \n",
    "* 해당 시간/주파수에서의 음파 강도에 따라 밝은색으로 표현  \n",
    "* wav 데이터가 단위 시간만큼 Short Time Fourier Transform을 진행해 매 순간의 주파수 데이터들을 얻어서 Spectrogram을 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-patrick",
   "metadata": {},
   "source": [
    "`pip install librosa`   <- `liblosa` 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aboriginal-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# 1차원 웨이브 데이터를 2차원 스펙토그램 데이터로 바꿔서 분류한다고 이해했는데 맞는지 모르겠음...\n",
    "# 아무튼 일단 웨이브->스펙으로 바꾸는 함수 정의!!\n",
    "def wav2spec(wav, fft_size=258): # spectrogram shape을 맞추기위해서 size 변형\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "still-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform shape :  (8000,)\n",
      "Spectrogram shape :  (130, 126)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "spec = wav2spec(data1[rand]) # 웨이브 데이터를 스펙토그램으로 변환 (1-dim data -> 2-dim data)\n",
    "print(\"Waveform shape : \",data1[rand].shape) #웨이브 데이터 8000개??\n",
    "print(\"Spectrogram shape : \",spec.shape)\n",
    "print(type(spec))\n",
    "\n",
    "spec = np.array(spec, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technical-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50620, 130, 126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_data = []\n",
    "#for wav in data1[0]:  <- 이건 행벡터 하나 뽑아서 예시로 보여준 것인듯... \n",
    "#모든 데이터를 스펙으로 바꿔야 한다면 아래 코드가 맞는듯.... 그래야 라벨 데이터랑 수가 맞으니까\n",
    "for i in range(0,len(data1)):\n",
    "    spec = wav2spec(data1[i])\n",
    "    spec_data.append(spec)\n",
    "    \n",
    "spec_data = np.array(spec_data)\n",
    "spec_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-pitch",
   "metadata": {},
   "source": [
    "### 라벨 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "official-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL :  ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n",
      "Indexed LABEL :  {'yes': 0, 'no': 1, 'up': 2, 'down': 3, 'left': 4, 'right': 5, 'on': 6, 'off': 7, 'stop': 8, 'go': 9, 'unknown': 10, 'silence': 11}\n"
     ]
    }
   ],
   "source": [
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')\n",
    "\n",
    "print('LABEL : ', label_value)\n",
    "\n",
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "    \n",
    "label_value = new_label_value\n",
    "\n",
    "print('Indexed LABEL : ', new_label_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "billion-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50620, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for v in data2:\n",
    "    temp.append(data2[rand])\n",
    "label_data = np.array(temp)\n",
    "\n",
    "label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alternate-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50620\n",
      "50620\n"
     ]
    }
   ],
   "source": [
    "print(len(spec_data))\n",
    "print(len(label_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-diana",
   "metadata": {},
   "source": [
    "### 학습을 위한 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-newton",
   "metadata": {},
   "source": [
    "* sklearn의 train_test_split 함수 이용 : train data와 test data 분리  \n",
    "* test_size의 인자를 조절해주면, 설정해 준 값만큼 Test dataset의 비율을 조정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "peripheral-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "# len(spec_data)와 len(label_data) 같으니까 실행되겠지??\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sr = 130\n",
    "sc = 126\n",
    "\n",
    "train_spec, test_spec, train_label, test_label = train_test_split(spec_data,\n",
    "                                                                  label_data,\n",
    "                                                                test_size=0.1,\n",
    "                                                                shuffle=True)\n",
    "#print(train_wav)\n",
    "\n",
    "train_spec = train_spec.reshape([-1, sr, sc,1]) # add channel for CNN\n",
    "test_spec = test_spec.reshape([-1, sr, sc,1])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-andorra",
   "metadata": {},
   "source": [
    "* 분리된 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unknown-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data :  (45558, 130, 126, 1)\n",
      "train labels :  (45558, 1)\n",
      "test data :  (5062, 130, 126, 1)\n",
      "test labels :  (5062, 1)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"train data : \", train_spec.shape)\n",
    "print(\"train labels : \", train_label.shape)\n",
    "print(\"test data : \", test_spec.shape)\n",
    "print(\"test labels : \", test_label.shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-defeat",
   "metadata": {},
   "source": [
    "### Hyper-parameters setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-member",
   "metadata": {},
   "source": [
    "* 학습을 위한 하이퍼파라미터 설정  \n",
    "* 모델 체크포인트 저장을 위한 체크포인트의 경로 설정  \n",
    "* 후에 모델 체크포인트 Callback 함수를 설정하거나, 모델을 불러올 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consecutive-giant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel-dj42/aiffel/speech_recognition/models/wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "\n",
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/speech_recognition/models/wav'\n",
    "\n",
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-updating",
   "metadata": {},
   "source": [
    "### Data setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-escape",
   "metadata": {},
   "source": [
    "* `tf.data.Dataset`을 이용하여 데이터셋 구성 (`Tensorflow`에 포함된 데이터셋 관리 패키지)  \n",
    "* 위 패키지는 데이터셋 전처리, 배치처리 등을 쉽게 할 수 있도록 해 줌  \n",
    "* `tf.data.Dataset.from_tensor_slices` 함수에 return 받길 원하는 데이터를 튜플 (data, label) 형태로 넣어서 사용  \n",
    "  \n",
    "* map 함수는 dataset이 데이터를 불러올때마다 동작시킬 데이터 전처리 함수를 매핑해 주는 역할  \n",
    "* 첫번째 map 함수는 `from_tensor_slice` 에 입력한 튜플 형태로 데이터를 받으며 return 값으로 어떤 데이터를 반환할지 결정  \n",
    "* map 함수는 중첩해서 사용 가능  \n",
    "  \n",
    "* 아래와 같이, map 함수에 넘겨줄 데이터 전처리 함수를 작성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mediterranean-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "# 여기부턴 진짜 모르겠음... 뭔 소리인지.... 난 최선을 다했다.... ㅠㅠㅠ\n",
    "def one_hot_label(wav, label):\n",
    "    wav = \n",
    "    label = tf.one_hot(label_data, depth=12)\n",
    "    return wav, label\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-broadcasting",
   "metadata": {},
   "source": [
    "* `tf.data.Dataset` 함수 구성  \n",
    "* `batch`는 dataset에서 제공하는 튜플 형태의 데이터를 얼마나 가져올지 결정하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "capital-modeling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-12-740a6a900a6a>:3 one_hot_label  *\n        label = tf.one_hot(label_data, depth=12)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper  **\n        return target(*args, **kwargs)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4010 one_hot\n        name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:6200 one_hot\n        off_value=off_value, axis=axis, name=name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:578 _apply_op_helper\n        param_name=input_name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:61 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: uint8, int32, int64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af58702c83c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \"\"\"\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3981\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3982\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3983\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3212\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3213\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-12-740a6a900a6a>:3 one_hot_label  *\n        label = tf.one_hot(label_data, depth=12)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper  **\n        return target(*args, **kwargs)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4010 one_hot\n        name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:6200 one_hot\n        off_value=off_value, axis=axis, name=name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:578 _apply_op_helper\n        param_name=input_name)\n    /home/aiffel-dj42/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:61 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: uint8, int32, int64\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_spec, train_label))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_spec, test_label))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-crisis",
   "metadata": {},
   "source": [
    "## 2. 스펙토그램 classification 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-government",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_tensor = layers.Input(shape=(sr, sc, 1))  # sc 추가해서 차원 맞춰주고\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor)  # Conv1D는 Conv2D로, 9는 (3,3)으로 변경\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_wav = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_wav.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-interaction",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-forge",
   "metadata": {},
   "source": [
    "* 현재 라벨이 될 수 있는 12개의 단어 class 가지고 있음  \n",
    "* 해당 class를 구분하기 위해 `multi-class classification` 필요  \n",
    "* 이를 수행하기 위한 `Loss`로 `Categorical Cross-Entropy loss`를 사용할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "model_wav.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-assets",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-alias",
   "metadata": {},
   "source": [
    "#### Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-drawing",
   "metadata": {},
   "source": [
    "* `model.fit` 함수를 이용할 때, `callback` 함수를 이용하여 학습 중간 중간 원하는 동작을 하도록 설정 가능  \n",
    "* 모델을 재사용하기 위해 모델 가중치를 저장하는 `callback` 함수 추가  \n",
    "  \n",
    "* `Model Checkpoint callback`은 모델을 학습을 진행하며, `fit` 함수 내 다양한 인자를 지정해 모니터하며 동작하게 설정 가능  \n",
    "* 현재 모델은 `validation loss`를 모니터하며, `loss`가 낮아지면 모델 파라미터를 저장하도록 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-legislature",
   "metadata": {},
   "source": [
    "* 아래는 모델 학습 코드  \n",
    "* 이전 스텝의 하이퍼파라미터 세팅에서 `batch_size=32, max_epochs=10`으로 세팅한 경우라면 30분 가량 소요될 것  \n",
    "* 메모리 사용량에 주의하며 적절히 하이퍼파라미터 세팅을 조절  \n",
    "* 메모리가 부족하다면 batch_size를 작게 조절해 주는게 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30분 내외 소요 (메모리 사용량에 주의해 주세요.)\n",
    "history_wav = model_wav.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_spec) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_spec) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-enhancement",
   "metadata": {},
   "source": [
    "### 학습 결과 Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-measure",
   "metadata": {},
   "source": [
    "* `model.fit` 함수는 학습 동안의 결과를 return  \n",
    "* return 값을 기반으로 loss와 accuracy를 그래프로 표현  \n",
    "* `fit` 함수에서 전달 받은 Loss와 Accuracy의 값을 이용해 모델이 어떻게 학습되고 있는지 확인 가능  \n",
    "* `train loss`와 `val_loss`의 차이가 커지는 경우 오버피팅이 일어나는 것이기 때문에 이를 수정할 필요가 있음  \n",
    "  \n",
    "* 출력된 그래프를 기반으로 모델의 학습이 어떻게 진행됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_wav.history['accuracy']\n",
    "val_acc = history_wav.history['val_accuracy']\n",
    "\n",
    "loss=history_wav.history['loss']\n",
    "val_loss=history_wav.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-variety",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-aspect",
   "metadata": {},
   "source": [
    "* Test dataset을 이용해서 모델의 성능 평가  \n",
    "  \n",
    "* 실습삼아 `checkpoint callback` 함수가 저장한 weight를 다시 불러와서 테스트 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wav.load_weights(checkpoint_dir)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-consumer",
   "metadata": {},
   "source": [
    "* Test data을 이용하여 모델의 예측값과 실제값이 얼마나 일치하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_wav.evaluate(test_dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-storm",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-personality",
   "metadata": {},
   "source": [
    "* Test data 셋을 골라 직접 들어보고 모델의 예측이 맞는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_label_value = {v: k for k, v in label_value.items()}\n",
    "batch_index = np.random.choice(len(test_wav), size=1, replace=False)\n",
    "\n",
    "batch_xs = test_wav[batch_index]\n",
    "batch_ys = test_label[batch_index]\n",
    "y_pred_ = model_wav(batch_xs, training=False)\n",
    "\n",
    "print(\"label : \", str(inv_label_value[batch_ys[0]]))\n",
    "\n",
    "ipd.Audio(batch_xs.reshape(8000,), rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-consciousness",
   "metadata": {},
   "source": [
    "* 위에서 확인해본 테스트셋의 라벨과 우리 모델의 실제 prediction 결과를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(y_pred_) == batch_ys[0]:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Correct!)')\n",
    "else:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Incorrect!)')\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-pontiac",
   "metadata": {},
   "source": [
    "## 3. Skip-Connection model을 추가해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-coach",
   "metadata": {},
   "source": [
    "### Skip-Connection model 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-nothing",
   "metadata": {},
   "source": [
    "* 기존의 모델을 `skip-connection`이 추가된 모델로 변경해 학습을 진행  \n",
    "* 위쪽의 데이터가 레이어를 뛰어넘어 레이어를 통과한 값에 더해주는 형식으로 구현  \n",
    "* Concat을 이용한 방식으로 구현  \n",
    "  \n",
    "* `tf.concat([#layer output tensor, layer output tensor#], axis=#)`  \n",
    "  \n",
    "* 우리가 사용하는 데이터가 1차원 audio 데이터이기 때문에 1차원 데이터를 처리하는 모델을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(sr, sc, 1))  # 여기 마찬가지로 sc 추가\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor) # Conv1D는 Conv2D로, 9는 (3,3)으로 변경\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "skip_1 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(skip_1)\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_1], -1)\n",
    "skip_2 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(skip_2)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_2], -1)\n",
    "skip_3 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(skip_3)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_3], -1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_wav_skip = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_wav_skip.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-reason",
   "metadata": {},
   "source": [
    "* 모델 구성만 달라졌을 뿐, 그 외 Task구성이나 데이터셋 구성, 훈련 과정은 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "model_wav_skip.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/speech_recognition/models/wav_skip'\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30분 내외 소요\n",
    "history_wav_skip = model_wav_skip.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-pearl",
   "metadata": {},
   "source": [
    "### 학습결과의 시각화 및 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_wav_skip.history['accuracy']\n",
    "val_acc = history_wav_skip.history['val_accuracy']\n",
    "\n",
    "loss=history_wav_skip.history['loss']\n",
    "val_loss=history_wav_skip.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "\n",
    "model_wav_skip.load_weights(checkpoint_dir)\n",
    "results = model_wav_skip.evaluate(test_dataset)\n",
    "\n",
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "inv_label_value = {v: k for k, v in label_value.items()}\n",
    "batch_index = np.random.choice(len(test_wav), size=1, replace=False)\n",
    "\n",
    "batch_xs = test_wav[batch_index]\n",
    "batch_ys = test_label[batch_index]\n",
    "y_pred_ = model_wav_skip(batch_xs, training=False)\n",
    "\n",
    "print(\"label : \", str(inv_label_value[batch_ys[0]]))\n",
    "\n",
    "ipd.Audio(batch_xs.reshape(8000,), rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-penetration",
   "metadata": {},
   "source": [
    "### 위에서 확인해본 테스트셋의 라벨과 우리 모델의 실제 prediction 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(y_pred_) == batch_ys[0]:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Correct!)')\n",
    "else:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Incorrect!)')\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-vehicle",
   "metadata": {},
   "source": [
    "## 4. 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-prefix",
   "metadata": {},
   "source": [
    "데이터 준비하기부터 이해가 안 가서 전 과정이 이해가 안 간다.  \n",
    "1차원 데이터를 2차원 데이터로 변경한 후 분류하는 과정이라고 이해했는데, 내가 지금 대체 데이터 수를 제대로 이해했는지도 모르겠고, 전반적인 이해도 프로젝트를 고민할 시간도 많이 부족했던 것 같다.  \n",
    "다시 만나고 싶지 않은 음성데이터... 최선을 다했음... 미래의 나에게 나머지 부분을 맡긴다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
